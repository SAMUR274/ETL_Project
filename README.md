# Advanced ETL Pipeline with Apache Airflow

[![Airflow](https://img.shields.io/badge/Airflow-2.x-green)](https://airflow.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸš€ Overview

Advanced ETL implementation showcasing distributed data processing using Apache Airflow. Features dynamic task mapping, containerization, and real-time API integration.

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ example_astronauts/    # Space station crew ETL
â”œâ”€â”€ Dockerfile                 # Runtime config
â”œâ”€â”€ include/                   # Resources
â”œâ”€â”€ packages.txt              # OS dependencies
â”œâ”€â”€ requirements.txt          # Python packages
â”œâ”€â”€ plugins/                  # Airflow plugins
â””â”€â”€ airflow_settings.yaml     # Environment config
```

## ğŸ”§ Core Components

- ğŸ—„ï¸ **PostgreSQL** (5432): Metadata storage
- ğŸŒ **Airflow UI** (8080): Web interface
- âš™ï¸ **Scheduler**: Task orchestration
- ğŸ”„ **Triggerer**: Async execution

## ğŸš¦ Quick Start

```bash
# Launch services
astro dev start

# Verify deployment
docker ps

# Access UI
open http://localhost:8080
credentials: admin/admin

# Database
postgresql://localhost:5432/postgres
```

## ğŸ“š Documentation

For deployment details, visit [Astronomer Docs](https://www.astronomer.io/docs/astro/deploy-code/)

## ğŸ¤ Support

Need help? Reach out to our support team for assistance.

---
Built with â¤ï¸ using Astronomer
